---
layout: post
title:  "Kaggle_intro"
subtitle:   "1"
categories: study
tags: kaggle
comments: true




---



### 캐글(Kaggle)_Intro

---

<br/>

#### 캐글이란?

- 머신러닝 경진대회 플랫폼

- 기업 - 우승자의 코드를 통해 내부 머신러닝 알고리즘 고도화  

  개인 - 데이터 직접 다루는 기회, 고액의 상금

<br/>

<br/>

#### 경진대회 유형

- `피쳐드 (Featured)` : **일반적인 경진대회**. 외부기업과 캐글이 연계해서 진행되는 상금 + 캐글 포인트 할당

<br/>

- `입문자용 (Getting Started)` : **예제 기반 학습용 경진대회**. 상금X, 캐글 포인트 X

<br/>

- `연구 (Research)` : **연구목적 경진대회**. 적은 상금 (피쳐드 대비)

<br/>

- `놀이터 (Playground)` : **캐글이 직접 주최하는 경진대**회. 상금이 할당되는 경우도 있다.

<br/>

- `채용 (Recruitment)` : **채용목적 경진대회**. 채용 면접권 + 캐글 포인트





##### 구조

1. **Overview** -경진대회를 주최하게 된 배경 /경진대회에 출제되는 문제

- Evaluation : 평가 척도

- SubmissionFile : 최종 예측 파일의 예시

- Timeline : 경진대회 스케줄 (미국 서부시간 기준으로 진행)

<br/>

2. **Data** - 경진대회에 사용되는 training data, test data, result sample을 다운로드 할 수 있다.

<br/>

3. **Kernels** - 대회와 관련된 소스코드들이 공유되는 장소.

<br/>

4. **Discussion** - 게시판. 질의응답, 데이터에 대한 궁금한 사항, 모델에 대한 질문 등. 대회가 끝나면 입상자들이 자신의 우승 코드를 공유, 설명 하기도 함.

<br/>

5. **Leaderboard** - 참가자의 순위. 팀 랭킹, 팀 멤버, 팀 점수, 결과물을 몇 번 제출했는지, 마지막으로 제출한 시간이 언제인지 등

- Public Leaderboard - test data의 일부로 매겨지는 랭킹. 

- Private Leaderboard - 최종 랭킹은 Public Leaderboard에 사용되지 않은 test data를 기반으로 매겨짐.

<br/>

---

#### 캐글을 시작하는 방법

<br/>

##### 1. 캐글 경진대회에 참여하는 목적을 정의한다

- 새로운 분야의 문제를 푸는 경험을 해보고 싶은건지
- 익숙한 분야의 문제에 새로운 알고리즘을 적용해 보고 싶은건지
- 익숙한 분야에서 익숙한 알고리즘으로 경진대회 상위 입상을 하고 싶은건지

<br/>

**2. 참여할 경진대회를 설정한다.**

- 머신러닝 알고리즘 직접 학습이 목적이라면? _ *이미 종료된 과거 경진대회.* 

  - why? 시간 충분. 학습에만 집중. 제출횟수 제한x, 


  - 데이터 누출 (Data Leakage)가 없는 경진대회
  - Leaderboard에서 상위 입상자들의 Submission 개수가 200개 이하인 경진대회

<br/>

**3. 데이터를 이해한다. (EDA)**

- 데이터 다운로드 및 탐색
- 눈으로 훑어보고, 기초통계/시각화 (변수 간 관계 scatter plot)

<br/>

**4. 평가 척도 이해하기**

- 경진대회 문제 의도 이해하기
- 어떤 예측값이 페널티를 크게받고, 어떤 예측값이 페널티를 덜 받는지 이해

<br/>

**5. 교차 검증 기법 선정 (Cross validation)**

- 신뢰할 수 있는 교차 검증 기법 구축하는 것이 중요함

<br/>

  - <u> 일반적인 교차검증 방법</u>

    1)  제공된 data를 5:5 ~9:1 비율로 train/test data로 분리한다

    2) train data에 머신러닝 모델을 학습하고, test data에서 평가 척도 점수를 구한다

    3) 1~2번을 10번 반복하여 검증 데이터에 대한 평균 점수를 구한다

    <br/>

    - <u>알아두면 좋을 내용</u>
      - train/test data의 분리비율 - 데이터가 많을 때는 5:5, 6:4 / 데이터가 적을 경우에 9:1.
      - 데이터를 분리할때는 random_seed값을 고정한다. random split 혹은 stratified split(계층별 분리)를 수행한다.
      - 1) 2)를 반복하는 횟수는 데이터의 크기와 한번 모델 학습을 하는데 걸리는 시간에 따라 결정한다.	

<br/>

**6. 피처 엔지니어링 (Feature engineering)**

- 데이터 전처리 과정 ( 변수 값 스케일링, 이상값 제거, 결측값 대체, 범주형 데이터 변환, 변수 선정, 파생 변수 생성 등)
- 핵심 요인

<br/>

**7. 모델 튜닝 (Model tuning)**

- 머신러닝 모델의 최적 파라미터를 찾음
- 신뢰할 수 있는 교차 검증 기법이 구축되었다면, 교차 검증 점수가 좋은 파라미터가 최적의 파라미터
- 중간 결과를 항상 저장해야함

<br/>

**8. 앙상블 (Ensemble)**

- 서로 다른 유형의 모델을 앙상블 한 것이 가장 좋은 성능을 보임
- 다수의 모델을 학습하는 스태킹 (Stacking)기법도 캐글 경진대회에서 자주 사용되는 앙상블 기법

<br/>

<br/>

#### 실질적인 팁

- <u>하드웨어</u> 

  - 최소사양 : 램16+gb, cpu 4+

  - 권장사양 : 램32+gb, cpu 8+


  **이미지,음성데이터를 다루고 딥러닝을 사용하는 경우**

  gpu의 크기가 한 번 학습할 때 모델이 활용할 수 있는 데이터의 개수(batch)를 정함

  - 최소사양 : gpu 램 4gb (gtx 970)
  - 권장사양 : gpu 램 8gb (gtx 1080)

<br/>

- <u>소프트웨어 라이브러리</u>

  - 데이터 전처리 - *numpy , pandas*
  - 데이터 시각화 - *matplotlib, seaborn*

  - 많이 사용되는 모델 
    - Gradient Boosting Decision Tree 라이브러리 _ *XGBoost, LightGBM, CatBoost*
    - 모델의 다양성을 위한 Bagging 기반 RandomForest, ExtraTrees 모델을 제공하는 *Scikit-learn*
  - 신경망 네트워크 모델 - *PyTorch, Keras*
  - 변수 특징이 선형모델이 좋을 때 - SVM, Logistic Regression (in *Scikit-learn*)
  - 램에 담을 수 없는 대규모 데이터를 처리할 때 - *Vowpal Wabbit*
  - 하이퍼 파라미터 최적화 작업 - hyperopt, scikit-optimize, spearmint 등의 *AutoML* 

<br/>

- <u>Baseline 모델</u>
  - 최소한의 성능을 보이는 기본 머신러닝 파이프라인 의미
    - 머신러닝 파이프라인이 올바르게 동작하는지 확인할 수 있음
    - 새로운 아이디어를 구현한 모델의 성능을 비교할 수 있는 기준점

<br/>

- 재현성
  - 사용하는 코드는 언제든지 재현할 수 있도록 해야
  - random_seed 고정, git을 이용해 손쉽게 과거 코드 불러올 수 있어야

<br/>

- 포기하지 않는 정신
  - 시도했던 것들, 배운 내용을 문서 형태로 저장

<br/>

- 팀으로 참여하기

  - 경진대회 참여 도중에 Discussion 게시판을 통해 동료 모집도 할 수 있음

  - 대회 종료 직전에는 자신과 비슷한 랭킹에 위치한 사용자와 팀을 맺기도 함
