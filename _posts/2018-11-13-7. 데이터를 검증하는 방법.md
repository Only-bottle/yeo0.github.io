---
layout: post
title:  "7. 데이터를 검증하는 방법"
subtitle:   "7"
categories: study
tags: ml
comments: true



---



## 파이썬을 이용한 머신러닝, 딥러닝 실전개발 입문

##### [파이썬을 이용한 머신러닝, 딥러닝 실전개발 입문](http://wikibook.co.kr/python-machine-learning/) 책과 [강의](https://www.youtube.com/playlist?list=PLBXuLgInP-5m_vn9ycXHRl7hlsd1huqmS)를 바탕으로한 코드 리뷰 및 정리입니다. 자세한 내용은 책과 강의를 참고해주세요.

##### link: [*github*](https://github.com/Yeo0/Machine-Learning/blob/master/4-7.%20%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%A5%BC%20%EA%B2%80%EC%A6%9D%ED%95%98%EB%8A%94%20%EB%B0%A9%EB%B2%95.ipynb)

<br/>

### 4. 머신러닝

#### 4-7. 데이터를 검증하는 방법

<br/>

##### Cross validation

- 교차검증 : 머신러닝 모델의 타당성을 검증하는 방법.

##### <br/>

#### K-fold cross validation

- 가장 많이 사용하는 교차검증 방법.

- train data 내에서 k번 train /test set을 번갈아 분할하고 학습하여 이를 통해 구한 정확도를 평균을 내어 최종 정확도를 구한다.

![img](https://www.researchgate.net/publication/320270458/figure/fig3/AS:551197158850560@1508427051009/K-fold-cross-validation-E-is-the-overall-error-estimate.png)

<br/>

#### 실습

- Iris 데이터를 5-fold-cross validation을 사용하여 정답률을 구한다.
- scikit-learn의 cross validation 메소드를 사용하지 않고 직접 구현해 보았다.

```python
from sklearn import svm, metrics
import random, re

lines=open("iris.csv",'r',encoding='utf-8').read().split('\n')
f_tonum=lambda n: float(n) if re.match(r'^[0-9\.]+$', n) else n 
f_cols=lambda li: list(map(f_tonum,li.strip().split(',')))
csv=list(map(f_cols,lines))
del csv[0] # 헤더제거
random.shuffle(csv)

#데이터 k개로 분할
k=5
csvk=[ [] for i in range(k)]
for i in range(len(csv)):
    csvk[i%k].append(csv[i])

#리스트를 훈련  전용 데이터와 테스트 전용 데이터로 분할
def split_data_label(rows):
    data=[]
    label=[]
    for row in rows:
        data.append(row[0:4])
        label.append(row[4])
    return (data, label)

#정답률
def calc_score(test,train):
    test_f, test_l=split_data_label(test)
    train_f, train_l=split_data_label(train)
    #학습시키고 정답률 구하기
    clf=svm.SVC()
    clf.fit(train_f, train_l)
    pre=clf.predict(test_f)
    return metrics.accuracy_score(test_l,pre)

#k개로 분할해서 정답률 구하기
score_list=[]
for testc in csvk:
    #testc이외의 데이터를 훈련 전용 데이터로 사용
    trainc=[]
    for i in csvk:
        if i != testc: trainc +=i
    sc=calc_score(testc, trainc)
    score_list.append(sc)
    
print("각각의 정답률=", score_list)
print("평균 정답률=", sum(score_list)/ len(score_list))
    
```

<br/>

- scikit-learn의 메소드를 사용하는 방법

```python
#scikitlearn의 crossvalidation
import pandas as pd
from sklearn import svm, metrics, model_selection
import random, re

#iris data 불러오기
csv=pd.read_csv("iris.csv")

#train / test set 분리
data=csv[["SepalLength", "SepalWidth", "PetalLength", "PetalWidth"]]
label=csv["Name"]

#cross validation
clf=svm.SVC()
scores=model_selection.cross_val_score(clf, data, label, cv=5)
print("각각의 정답률=", scores)
print("평균 정답률=", scores.mean())
```

<br/>

#### 그리드 서치

- 각 알고리즘에서 필요한 매개변수들을 튜닝하는 방법.
- 어떤 매개변수 조합이 적절한지 자동으로 조사하는 것이다. 각 매개변수를 적당한 범위 내부에서 변경하면서 가장 성능이 좋을때의 값을 찾는다. 대신 시간이 좀 걸린다..
- 이전에 살펴본 [MNIST](https://yeo0.github.io/study/2018/10/24/3.-%EC%9D%B4%EB%AF%B8%EC%A7%80-%EB%82%B4%EB%B6%80%EC%9D%98-%EB%AC%B8%EC%9E%90-%EC%9D%B8%EC%8B%9D/) 데이터를 활용하여 파라미터 튜닝을 진행해 보려 한다.

```python
# Grid search
import pandas as pd
from sklearn import model_selection, svm, metrics
from sklearn.grid_search import GridSearchCV

#MNIST 데이터 불러오기
train_csv=pd.read_csv("./mnist/train.csv")
test_csv=pd.read_csv("./mnist/t10k.csv")

#필요 열 추출
train_label=train_csv.ix[:,0]
train_data=train_csv.ix[:,1:577]
test_label=test_csv.ix[:,0]
test_data=test_csv.ix[:,1:577]
print("학습 데이터의 수=", len(train_label))

#그리드서치 매개변수 설정 #후보지정
params=[
    {"C":[1,10,100,1000],"kernal":["linear"]},
    {"C":[1,10,100,1000],"kernal":["rbf"],"gamma":[0.001,0.0001]}
]

#그리드서치 수행
clf=GridSearchCV(svm.SVC(),params, n_jobs=-1) #GridSerarchCV(분류기, 파라미터후보들, 병렬프로세수 수) / n_jobs=-1일 경우 자동으로 코어수에 맞게 프로세스 수 설정
clf.fit(train_data, train_label)
print("학습기=",clf.best_estimator_)

#테스트 데이터 확인
pre=clf.predict(test_data)
as_score=metrics.accuracy_score(pre,test_label)
print("정답률=",ac_score)
```

