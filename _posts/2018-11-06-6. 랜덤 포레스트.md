---
layout: post
title:  "6. 랜덤 포레스트"
subtitle:   "6"
categories: study
tags: ml
comments: true


---



## 파이썬을 이용한 머신러닝, 딥러닝 실전개발 입문

##### [파이썬을 이용한 머신러닝, 딥러닝 실전개발 입문](http://wikibook.co.kr/python-machine-learning/) 책과 [강의](https://www.youtube.com/playlist?list=PLBXuLgInP-5m_vn9ycXHRl7hlsd1huqmS)를 바탕으로한 코드 리뷰 및 정리입니다. 자세한 내용은 책과 강의를 참고해주세요.

##### link: [*github*](https://github.com/Yeo0/Machine-Learning/blob/master/4-6.%20%EB%9E%9C%EB%8D%A4%ED%8F%AC%EB%A0%88%EC%8A%A4%ED%8A%B8.ipynb)

<br/>

### 4. 머신러닝

#### 4-6. 랜덤 포레스트

<br/>

책의 이론들은 상대적으로 많이 부실해 나중에 제가 따로 정리하도록 하고, 랜덤포레스트의 실습 위주로 정리해보려 합니다.

<br/>

#### 랜덤포레스트 (Random forest)

간단히 설명하면 train data를 무작위로 sampling 해 만든 다수의 Decision tree를 기반으로 다수결로 결과를 추출한다.

![img](https://ai2-s2-public.s3.amazonaws.com/figures/2017-08-08/639f3ed1831071861fe4dd81653fa064dec27864/8-Figure2-1.png)



<br/>

#### 실습

- 이용할 데이터는 http://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/ 에서의 [agaricus-lepiota.data](http://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data) 입니다.

- 데이터의 첫 열은 버섯을 독의 유무에 따라 분류에 놓은 것 입니다.
  - p (poisonous) / e (edible)
- 나머지 열은 버섯 머리모양, 버섯 머리색, 버섯 형태 등 다양한 정보를 담았으며, 이 데이터들로 독의 유무를 예측하는 코드를 만들 것 입니다.

```python
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn import metrics
from sklearn.model_selection import train_test_split

#데이터 읽기
mr=pd.read_csv("mushroom.csv", header=None)

#데이터 내부의 기호를 숫자로 변환하기
label=[] #p,e
data=[]
attr_list=[]

print(mr[0])

for row_index, row in mr.iterrows():
    label.append(row.ix[0]) #ix=특정행을 지정하는 방법
    row_data=[]
    for v in row.ix[1:]:
        row_data.append(ord(v)) #알파벳 -> 숫자 변환
    data.append(row_data)
    
#학습 전용과 테스트 전용 데이터로 나누기
data_train, data_test, label_train, label_test=train_test_split(data, label)

#데이터 학습시키기
clf=RandomForestClassifier()
clf.fit(data_train, label_train)

#데이터 예측하기
predict=clf.predict(data_test)

#결과 테스트하기
ac_score=metrics.accuracy_score(label_test, predict)
cl_report=metrics.classification_report(label_test,predict)
print("정답률=", ac_score)
print("리포트=\n", cl_report)
```

<br/>

#### 문자->숫자 변환 시 유의점

- 그냥 단순한 분류를 위한 변수인지, 연속성을 나타내는 변수인지를 확인해야 합니다.
- 연속성이없는 범주형 변수인 경우, one-hot 인코딩을 사용해야합니다. (자세한 건 따로 포스팅을 마련하려 한다.)

ex)

- 간단히 설명하면 빨강=1, 파랑=2, 초록=3, 흰색=4 인 데이터가 있다고 할 때 이를 그대로 쓰는게 아니라 아래와 같이 나타내는 것이다

```
빨강 = [1 0 0 0]
파랑 = [0 1 0 0]
초록 = [0 0 1 0]
흰색 = [0 0 0 1]
```

- 데이터의 범주가 많아질수록 크기가 커진다는 단점이 있지만 아직까지는 유용히 사용되는 방법입니다. 

- 아래는 위에서 사용한 데이터를 one-hot encoding을 사용해 예측한 코드입니다.

```python
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn import metrics
from sklearn.model_selection import train_test_split

#데이터 읽기
mr=pd.read_csv("mushroom.csv", header=None)

#데이터 내부의 기호를 숫자로 변환하기
label=[]
data=[]
attr_list=[]

for row_index, row in mr.iterrows():
    label.append(row.ix[0])
    exdata=[]
    for col, v in enumerate(row.ix[1:]):
        if row_index==0:
            attr={"dic":{},"cnt":0}
            attr_list.append(attr)
        else:
            attr=attr_list[col]
            
        #버섯의 특징 기호를 배열로 
        d=[0,0,0,0,0,0,0,0,0,0,0,0]
        if v in attr["dic"]:
            idx=attr["dic"][v]
        else:
            idx=attr["cnt"]
            attr["dic"][v]=idx
            attr["cnt"]+=1
        d[idx]=1
        exdata+=d
    data.append(exdata)
    
#학습 전용과 테스트 전용 데이터로 나누기
data_train, data_test, label_train, label_test=train_test_split(data, label)

#데이터 학습시키기
clf=RandomForestClassifier()
clf.fit(data_train, label_train)

#데이터 예측하기
predict=clf.predict(data_test)

#결과 테스트하기
ac_score=metrics.accuracy_score(label_test, predict)
cl_report=metrics.classification_report(label_test,predict)
print("정답률=", ac_score)
print("리포트=\n", cl_report)
```



